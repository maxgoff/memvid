<p align="center">
  <a href="https://github.com/memvid/memvid">
    <img src="assets/banner.png" width="800px" alt="Memvid ‚Äî Living Memory for AI">
  </a>
</p>

<p align="center">
  <strong>Memvid is a video-native memory engine for AI.</strong><br/>
  Persistent, versioned, and portable memory ‚Äî without databases.
</p>

<p align="center">
  <a href="https://www.memvid.com">Website</a>
  ¬∑
  <a href="https://docs.memvid.com">Docs</a>
  ¬∑
  <a href="https://github.com/memvid/memvid/discussions">Discussions</a>
</p>

<p align="center">
  <img src="https://img.shields.io/github/stars/memvid/memvid?style=flat-square" />
  <img src="https://img.shields.io/github/issues/memvid/memvid?style=flat-square" />
  <img src="https://img.shields.io/badge/status-v2%20in%20progress-blue?style=flat-square" />
</p>

---

<h2 align="center">‚≠êÔ∏è Star this repository to support Memvid ‚≠êÔ∏è</h2>

---

## üöÄ Memvid v2 launches **January 5, 2026**

> **Note**  
> Memvid v1 is deprecated and intentionally removed to avoid confusion.  
> This repository represents **Memvid v2**.

---

## What is Memvid?

Memvid turns knowledge into **living memory capsules** using video compression.

Instead of storing context in vector databases, Memvid encodes memory into
**video-native formats** that are compact, fast to recall, offline-first,
and future-proof through modern codecs.

Think of Memvid as **long-term memory infrastructure for LLMs**.

---

## Why Video?

Modern video codecs (H.265, AV1, and future standards) are among the most
optimized compression systems ever built.

Memvid leverages this ecosystem to deliver:

- Massive compression for large knowledge bases  
- Deterministic, reproducible recall  
- Zero infrastructure ‚Äî just files  
- Automatic improvements as codecs evolve  

---

## Core Concepts (v2)

- **Living Memory Engine**  
  Continuously append, branch, and evolve memory across sessions.

- **Capsule Context (`.mv2`)**  
  Self-contained, shareable memory capsules with rules and expiry.

- **Time-Travel Debugging**  
  Rewind, replay, or branch any memory state.

- **Smart Recall**  
  Sub-5ms local memory access with predictive caching.

- **Codec Intelligence**  
  Auto-selects and upgrades compression over time.

---

## Use Cases

- Long-running AI agents  
- Knowledge assistants  
- Offline-first AI systems  
- Auditable and debuggable AI workflows  

---

## Status

- Architecture locked  
- APIs stabilizing  
- Docs and SDKs coming soon  
- **Public v2 release: January 5, 2026**

---

## License

Apache License 2.0 ‚Äî see the [LICENSE](LICENSE) file for details.
